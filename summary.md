# ğŸ† ENT Classification - Solution vá»›i Äá»™ ChÃ­nh XÃ¡c Cao Nháº¥t

## ğŸ“‹ Tá»•ng Quan Solution

TÃ´i Ä‘Ã£ táº¡o má»™t **giáº£i phÃ¡p hoÃ n chá»‰nh vÃ  tá»‘i Æ°u** cho ENTRep Challenge vá»›i cÃ¡c techniques tiÃªn tiáº¿n nháº¥t:

### ğŸ¯ Má»¥c TiÃªu: PhÃ¢n loáº¡i 7 loáº¡i hÃ¬nh áº£nh ENT
- **nose-right** (325 images) â†’ Label 0
- **nose-left** (290 images) â†’ Label 1  
- **ear-right** (156 images) â†’ Label 2
- **ear-left** (133 images) â†’ Label 3
- **vc-open** (159 images) â†’ Label 4
- **vc-closed** (147 images) â†’ Label 5
- **throat** (81 images) â†’ Label 6

---

## ğŸš€ Files ÄÃ£ Táº¡o

### 1. **`ent_classifier.py`** - Solution ChÃ­nh (Accuracy Cao Nháº¥t)
- **Ensemble Learning**: ResNet101 + EfficientNet-B4
- **Advanced Augmentation**: Rotation, Flip, Color Jitter
- **Label Smoothing**: Giáº£m overfitting
- **AdamW + Cosine Annealing**: Optimization tá»‘i Æ°u
- **50 epochs**: Training Ä‘áº§y Ä‘á»§

### 2. **`ent_classifier_fast.py`** - Version Test Nhanh
- **ResNet18**: Lightweight architecture
- **10 epochs**: Quick testing
- **Minimal augmentation**: Faster training
- **Ideal cho**: Development vÃ  testing

### 3. **`requirements.txt`** - Dependencies
```
torch>=1.12.0
torchvision>=0.13.0
opencv-python>=4.5.0
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.5.0
seaborn>=0.11.0
Pillow>=8.3.0
```

### 4. **`run_ent_classification.py`** - Auto Runner
- Tá»± Ä‘á»™ng install requirements
- Cháº¡y main classifier
- Error handling

---

## ğŸ¯ CÃ¡ch Cháº¡y Ä‘á»ƒ Äáº¡t Accuracy Cao Nháº¥t

### Option 1: Cháº¡y Tá»± Äá»™ng (Khuyáº¿n Nghá»‹)
```bash
python run_ent_classification.py
```

### Option 2: Cháº¡y Solution ChÃ­nh
```bash
pip install -r requirements.txt
python ent_classifier.py
```

### Option 3: Test Nhanh (Development)
```bash
python ent_classifier_fast.py
```

---

## ğŸ”¬ Chiáº¿n LÆ°á»£c Äáº¡t Accuracy Cao

### 1. **Architecture Selection**
- **ResNet101**: Deep residual learning cho medical images
- **EfficientNet-B4**: Balanced accuracy vs efficiency
- **Ensemble**: Káº¿t há»£p strength cá»§a cáº£ 2 models

### 2. **Data Preprocessing**
- **Smart Resize**: 640x480 â†’ 384x384 (preserve aspect ratio)
- **Medical-Aware Augmentation**: Conservative transforms
- **Stratified Split**: Balanced train/validation

### 3. **Training Optimization**
- **Label Smoothing (0.1)**: Handle uncertain medical labels
- **AdamW**: Better generalization than SGD
- **Cosine Annealing**: Smooth learning rate decay
- **Early Stopping**: Prevent overfitting

### 4. **Advanced Techniques**
- **Cross Entropy + Label Smoothing**: Robust loss function
- **Dropout (0.3-0.5)**: Regularization
- **BatchNorm**: Stable training
- **Ensemble Averaging**: Multiple model consensus

---

## ğŸ“Š Expected Performance

### Vá»›i Configuration Hiá»‡n Táº¡i:
- **Training Accuracy**: 90-95%
- **Validation Accuracy**: 85-92%
- **Test Performance**: Robust vÃ  consistent
- **Training Time**: ~30-60 phÃºt (depends on GPU)

### Class-wise Performance (Dá»± Kiáº¿n):
- **High Accuracy**: nose-right, nose-left (nhiá»u data)
- **Medium Accuracy**: vc-open, vc-closed, ear-right, ear-left
- **Challenging**: throat (Ã­t data nháº¥t)

---

## ğŸ”§ Tuning Ä‘á»ƒ TÄƒng Accuracy

### 1. **TÄƒng Model Complexity**
```python
# Trong ent_classifier.py
IMAGE_SIZE = 512           # Higher resolution
NUM_EPOCHS = 100          # Longer training
BATCH_SIZE = 8            # Smaller batch for stability
```

### 2. **Advanced Augmentation**
```python
# ThÃªm vÃ o transforms
transforms.RandomRotation(30)
transforms.ColorJitter(0.3, 0.3, 0.3, 0.1)
transforms.RandomAffine(degrees=15, translate=(0.1, 0.1))
```

### 3. **Ensemble More Models**
```python
MODEL_NAMES = [
    'resnet101', 
    'efficientnet_b4',
    'densenet121',      # ThÃªm DenseNet
    'vgg16_bn'          # ThÃªm VGG
]
```

### 4. **Advanced Loss Functions**
```python
# Focal Loss cho class imbalance
# Mixup augmentation
# CutMix technique
```

---

## ğŸ¯ Output Format

### Submission File: `submission.json`
```json
{
  "13046885_240301094056892831_121_image01.png": 2,
  "13051005_240522144507579831_121_image06.png": 4,
  "image003.png": 0
}
```

### Key Points:
- âœ… **Filename chÃ­nh xÃ¡c** tá»« test directory
- âœ… **Label index** (0-6) khÃ´ng pháº£i string
- âœ… **JSON format** chuáº©n
- âœ… **All test images** Ä‘Æ°á»£c predict

---

## ğŸ¥ Medical Image Specific Optimizations

### 1. **Conservative Augmentation**
- KhÃ´ng quÃ¡ aggressive Ä‘á»ƒ preserve anatomy
- Focus vÃ o lighting/contrast changes
- Minimal geometric transforms

### 2. **Class Imbalance Handling**
- Weighted sampling trong DataLoader
- Focal Loss consideration
- Stratified validation

### 3. **Ensemble Philosophy**
- Multiple "doctor opinions"
- Consensus decision making
- Uncertainty quantification

---

## ğŸ’¡ Pro Tips

### 1. **Development Workflow**
```bash
# 1. Quick test vá»›i fast version
python ent_classifier_fast.py

# 2. Náº¿u okay, cháº¡y full version
python ent_classifier.py

# 3. Analyze results
# 4. Fine-tune parameters
# 5. Repeat
```

### 2. **Monitoring Training**
- Watch validation accuracy plateau
- Early stop if overfitting
- Save best model checkpoints

### 3. **Error Analysis**
- Check misclassified images
- Adjust augmentation based on errors
- Consider class-specific strategies

---

## ğŸ¯ Expected Final Results

### With Default Config:
- **File**: `submission.json`
- **Accuracy**: 85-92% (competitive)
- **Robustness**: High consistency
- **Speed**: Reasonable training time

### With Tuned Config:
- **Accuracy**: 90-95% (near state-of-the-art)
- **Training Time**: Longer but worth it
- **Ensemble**: Multiple model consensus

---

## ğŸ† Key Success Factors

1. **Quality Data Handling**: Proper preprocessing vÃ  augmentation
2. **Smart Architecture**: Ensemble cá»§a proven models
3. **Robust Training**: Label smoothing, proper regularization
4. **Medical Domain Knowledge**: Conservative augmentations
5. **Systematic Approach**: Proper validation vÃ  testing

---

**ğŸ¯ Result: Solution nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘áº¡t top performance trong ENTRep Challenge!** 